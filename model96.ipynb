{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "xynpNPvGO42h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC2fYf5YCThO"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J75lU-zBh1HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "JD0kcJz7jS-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='/content/drive/MyDrive/red spider final'\n"
      ],
      "metadata": {
        "id": "piTm9xhkh1Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_path)\n",
        "import os\n",
        "labels=[]\n",
        "for i in os.listdir(img_path):\n",
        "  if os.path.isdir(os.path.join(img_path,i)):\n",
        "    labels.append(i)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "6Zt6PPe9h1Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''from tensorflow.keras.utils import image_dataset_from_directory # Import the required function\n",
        "\n",
        "# Load dataset and split into train, validation, and test sets\n",
        "train_ds = image_dataset_from_directory(\n",
        "    img_path,\n",
        "    validation_split=0.3,  # 20% of data will be used for validation/testing\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),  # Resizing images for MobileNetV2\n",
        "\n",
        ")'''"
      ],
      "metadata": {
        "id": "ABORjnere2pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''val_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    img_path,\n",
        "    validation_split=0.3,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=BATCHSIZE\n",
        ")'''"
      ],
      "metadata": {
        "id": "aRGtG2XvgXup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j1eFkK8UNUOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "val_size = int(0.5 * tf.data.experimental.cardinality(val_test_ds).numpy())  # ~132 images\n",
        "val_ds = val_test_ds.take(val_size)\n",
        "test_ds = val_test_ds.skip(val_size)\n",
        "\n",
        "# Verify sizes (approximate due to batching)\n",
        "print(f\"Train size: {tf.data.experimental.cardinality(train_ds).numpy() * BATCHSIZE}\")\n",
        "print(f\"Val size: {tf.data.experimental.cardinality(val_ds).numpy() * BATCHSIZE}\")\n",
        "print(f\"Test size: {tf.data.experimental.cardinality(test_ds).numpy() * BATCHSIZE}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "PCK9LC4FGTZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE=32\n",
        "IMG_SIZE=224\n",
        "EPOCHS=100"
      ],
      "metadata": {
        "id": "sVG4_mZ1TGSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/red spider final\""
      ],
      "metadata": {
        "id": "8pUID9Z9LV1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "full_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    seed=123,\n",
        "    image_size=(IMG_SIZE,IMG_SIZE),\n",
        "  #  seed=123,\n",
        "    batch_size=BATCHSIZE\n",
        "\n",
        ")\n",
        "\n",
        "# Unbatch and get exact count\n",
        "images_labels = list(full_ds.unbatch())\n",
        "total_images = len(images_labels)  # 879\n",
        "print(f\"Total images: {total_images}\")\n",
        "\n",
        "# Separate images and labels\n",
        "images = [x[0] for x in images_labels]\n",
        "labels = [x[1] for x in images_labels]\n",
        "\n",
        "# Exact split\n",
        "train_size = int(0.7 * total_images)  # 615\n",
        "val_size = int(0.15 * total_images)   # 131\n",
        "test_size = total_images - train_size - val_size  # 133\n",
        "\n",
        "# Create datasets without padding\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (images[:train_size], labels[:train_size])\n",
        ").batch(BATCHSIZE, drop_remainder=True)  # Drop partial batches\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (images[train_size:train_size + val_size], labels[train_size:train_size + val_size])\n",
        ").batch(BATCHSIZE, drop_remainder=True)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (images[train_size + val_size:], labels[train_size + val_size:])\n",
        ").batch(BATCHSIZE, drop_remainder=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "M-0Frtt_NYFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sizes\n",
        "print(f\"Train size: {tf.data.experimental.cardinality(train_ds).numpy() * BATCHSIZE}\")\n",
        "print(f\"Val size: {tf.data.experimental.cardinality(val_ds).numpy() *BATCHSIZE}\")\n",
        "print(f\"Test size: {tf.data.experimental.cardinality(test_ds).numpy() * BATCHSIZE}\")\n",
        "\n",
        "# Verify actual counts\n",
        "print(f\"Actual Train: {len(list(train_ds.unbatch()))}\")\n",
        "print(f\"Actual Val: {len(list(val_ds.unbatch()))}\")\n",
        "print(f\"Actual Test: {len(list(test_ds.unbatch()))}\")"
      ],
      "metadata": {
        "id": "L4OF-QAOP14s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = full_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "y_A3E5SrS0D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualization\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(5):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "EFoqPc1gP5_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "lKJew4BRi_qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "RXRUMsM4VEze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizations_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "_x-uSeJ3jH-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds=train_ds.map(lambda x,y:(normalizations_layer(x),y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "jslfrpgmBPWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip('horizontal', input_shape=(IMG_SIZE, IMG_SIZE, 3)),  # Random horizontal flip\n",
        "    layers.RandomRotation(0.1),  # Random rotation (-20% to +20%)\n",
        "   # layers.RandomBrightness(factor=(0.7, 1.3)),  # Adjust brightness in the range 0.7–1.3\n",
        "    layers.RandomZoom(0.1)  # Random zoom by 5%\n",
        "])"
      ],
      "metadata": {
        "id": "eXM5PZUoka-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
        "\n",
        "                                            include_top=False, weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:120]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "IgRmColWkE8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_model.summary()"
      ],
      "metadata": {
        "id": "BQVJws7z70_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#setupe the model architecture\n",
        "l2_lambda =0.005\n",
        "inputs=keras.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
        "X=data_augmentation(inputs)\n",
        "x=keras.applications.mobilenet_v2.preprocess_input(X)\n",
        "x=base_model(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "#x=layers.Dense(512)(x)\n",
        "#x=layers.BatchNormalization()(x)\n",
        "#x = layers.ReLU()(x)\n",
        "\n",
        "x=layers.Dense(256,kernel_regularizer=tf.keras.regularizers.l2(l2_lambda))(x)\n",
        "\n",
        "x=layers.BatchNormalization()(x)\n",
        "x = layers.ReLU()(x)\n",
        "x=layers.Dense(128,kernel_regularizer=tf.keras.regularizers.l2(l2_lambda))(x)\n",
        "x=layers.BatchNormalization()(x)\n",
        "x = layers.ReLU()(x)\n",
        "x=layers.Dropout(0.6)(x)   #0.5\n",
        "\n",
        "\n",
        "#output layar\n",
        "# The prediction layer should match the output of the preceding layer.\n",
        "prediction_layer = tf.keras.layers.Dense(4, activation=\"softmax\")\n",
        "outputs=prediction_layer(x)\n",
        "model=keras.Model(inputs,outputs)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "80f817HUaVWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()"
      ],
      "metadata": {
        "id": "tryQPL3UehYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=3\n",
        "\n",
        "    )\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "JLuOPKN-qvuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert labels to NumPy array before concatenation\n",
        "labels = np.array([y.numpy() for _, y in train_ds.unbatch()])\n",
        "\n",
        "# Now you can use bincount\n",
        "print(np.bincount(labels))  # بيطبع عدد الصور لكل فئة\n"
      ],
      "metadata": {
        "id": "I_UpU0pXqWdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Ensure 'classes' is a NumPy array\n",
        "class_weights = compute_class_weight('balanced', classes=np.array([0, 1, 2, 3]), y=labels)\n",
        "class_weights_dict = dict(enumerate(class_weights))"
      ],
      "metadata": {
        "id": "qoszBHDjX6ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=1e-4"
      ],
      "metadata": {
        "id": "R_y_K9jpwBWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FZUdE_0b1DsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights_dict\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "hzYs415JjLA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "ZRLXMFKwUQl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('red_spider_91.35.h5')"
      ],
      "metadata": {
        "id": "v-29fJ15fpoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the model into tflite\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open('red_spider_91.35.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "eOOpkEOsgGqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs_range=range(EPOCHS)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs_range,acc,label='Training Accuracy')\n",
        "plt.plot(epochs_range,val_acc,label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs_range,loss,label='Training Loss')\n",
        "plt.plot(epochs_range,val_loss,label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ktQHzgLiV0xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "    return predicted_class, confidence"
      ],
      "metadata": {
        "id": "uZ6YpAmfdB3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in test_ds.take(5):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        predicted_class, confidence = predict(model, images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "9ZWJXGLNdB7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming 'model' and 'test_ds' are defined from the previous code\n",
        "\n",
        "# Get predictions on the test set\n",
        "y_pred = model.predict(test_ds)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=45)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# Add labels to each cell\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in np.ndindex(cm.shape):\n",
        "    plt.text(j, i, cm[i, j],\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QK5IThQ6dmSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print Precision, Recall, F1-score\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "id": "Ar-SA0ypPI75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "eeY4cRReUo4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}